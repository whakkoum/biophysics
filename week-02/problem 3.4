# Standard setup
import numpy as np
import matplotlib.pyplot as plt

# Get a random number generator.
from numpy.random import default_rng
rng = default_rng()
rand = rng.random

flips = 2*(rand(10) < 0.5) - 1
X = flips.sum()

print("Coin flips: ", flips)
print("Sum: X=", X)

    # part (a):

# Define the problem.
Ntrials = 10
Nflips = 10
Nstart = 5

# Create an array to store the data we want.
data = np.zeros(Ntrials)
count = 0

# Generate Ntrials sequences of Nflips coin flips, and sum.
for n in range(Ntrials):
    flips = 2*(rand(Nflips) < 0.5) - 1
    X = flips.sum()
    
    # Replace "if True:" with a conditional statement that will do the following.
    #    IF the first Nstart flips are heads, store X in "data" and increment "count".
    #    OTHERWISE, do nothing and continue to the next trial.
    if True:
        data[count] = X
        count += 1

# Now use the data set to answer the question.
if count == 0:
    print("No trials started with {} heads.".format(Nstart))
else:
    avgX = data[:count].sum() / count
    print ("There were {} trials that started with {} heads.".format(count,Nstart))
    print("The average of X for these trials was <X>= {:.4f}.".format(avgX))

plt.hist(data, rwidth=.9)
# I noticed that the pattern here is the fact that the resultant hisogram is always bell-shaped meaning that the values of the array are more concentrated around the middle (most of the time)
# I also noticed that the bar that has the largest number of values does not exceed one quarter of the total values (most of the time)
# Also, the bars are symmetrical also most of the time.

    # Part (b):

# Ntrials = 2,000 and Ntrials = 8,000
# As the number of values go up, the plot tends to become more and more symmetrical around the middle.
# It becomes perfectly symmetrical when we use even higher values, such as 1,000,000 for example. 

    # Part (c):
# This statistical phenomenon happens when the same topic or unit of measurement is measured many times. This occurs because the values are obvsered with random error. The variance of the data around the true mean is often called a random error.

    # Part (d):
# As the number of trials increases, the spread of the data in the x-direction increases as well. When I tried entering 100,000 values for Ntrials, the data spreads from -10 to 10 in the X-direction. When I entered 1000,000 for the Ntrials, nothing changes, so I think this is as wide as it can get.
# With that being said, the value of X (mean) is getting closer and closer to zero as the number of Ntrials increases.
    # Part (e):
# The first proposal worked a couple of times but not always. It is not consistent, but most of the time we get 5 or 6 tails after getting heads on the first coin flip. 
# I don't think the second proposal makes sense because I noticed that the effect of the unusual past behavior doesn't disappear and doesn't get diluted. It keeps oscillating back and forth
